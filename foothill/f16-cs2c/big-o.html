<!doctype html>
<html>
<head>
<title>Algorithm Analysis</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.2.0/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.2.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head>
<body>
<section>
  

<h2>Big-O</h2>
<p>Imagine that you have some algorithms you can choose from. You might be able to work on some of them and make them twice as fast or 10 times as fast, but you can only every make them some constant faster. Some algorithms are just slow for large inputs. For example, if you want to find something in an <code>std::vector</code> by looking at each element one at a time, no matter how fast you can look at each element, you still have to look at each element in the worst case. If you double N, the size of the input, then it will take twice as long. In other words, the simple search algorithm takes on the order of N steps. The number of steps is O(N). The run time is O(N). We could also say that it's O(2N) or O(3N), but since we don't care about constant speed ups, we just say O(N).</p>
<p>Big-O is all about how a function grows as it's input gets larger. For example, the amount of time that Binary Search takes only increases by 1 "step" when the input is doubled. If the input is 8 times as big, then it only takes 3 more "steps". Binary Search is O(log(N)), where N is the size of the input, because regardless of how fast each step is . It's not very useful for telling you which algorithm is faster for small input, but is very useful for telling you which one is faster for large input.</p>
<p>Let's say we have a function, f(N) and we want to prove that it's O(g(N)). f(N) <em>grows</em> about as fast or slower than g(N).  What this is saying is that f(N) is always less than c * g(N) for any N &ge; n.  Even if f(N) is bigger than g(N) when N is small, there's some point at/after which it is <em>always</em> smaller.  The National Insitute of Standards and Technology has a <a href="https://xlinux.nist.gov/dads/HTML/bigOnotation.html">nice graph and page that describes this, but with different variable names</a>.</p>
<img src="https://upload.wikimedia.org/wikipedia/commons/8/89/Big-O-notation.png" alt="f(N) is greather than g(N) until N &gt; n, then f(N) is always less than g(N).">
<p>We can use the definition of big-O. f(N) &isin; O(g(N)) if and only if there exists some constants c and n such that f(N) &le; c * g(N) for all N &gt; n. In the picture above n is X0.</p>
<h3>Example</h3>
<p>As an example, let's consider this <code class="c++">fibonacci_loop</code> function, which outputs the <a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci numbers</a>:</p>
<pre><code class="c++">long fibonacci_loop(int n) {
  long f0 = 0, f1 = 1, f2 = 1;  // 3 assignment operations
  while (n &gt;= 0) {  // loop runs n times (n comparison ops)
    f2 = f1 + f0;  // n * (1 addition op, 1 assignment op)
    f0 = f1;  // n * (1 assignment op)
    f1 = f2;  // n * (1 assignment op)
    n--;  // n * (1 decrement op)
  }
  return f2;  // 1 return
}
</code></pre>
<p>That looks like a lot of ops and there are a few different kinds of operations that are mixed together.  For now, let's just assume that all those operations are equal.  If they're all equal, then the total number of operations is T(N) == 3 + n + n * (2 + 1 + 1 + 1) + 1 == 6 * N + 4.  Let's also assume that the running time, T(N), of this algorithms is in O(N) and try to prove it.</p>
<p>If we can prove that there are a couple constants, c and n, such that T(N) &le; c * N whenever N &ge; n, then we win.  Let's try choosing c == 5 and see what happens.
<table>
  <tr><td>T(N)</td><td>&le;</td><td>c * N</td></tr>
  <tr><td>T(N)</td><td>&le;</td><td>5 * N</td></tr>
  <tr><td>6 * N + 4</td><td>&le;</td><td>5 * N</td></tr>
  <tr><td>N + 4</td><td>&le;</td><td>1</td></tr>
  <tr><td>N + 3</td><td>&le;</td><td>0</td></tr>
</table>
That didn't work!  In fact, not only did it not work, it almost makes it seem like T(N) is not O(N)... What if we tried a bigger constant, like 7?
<table>
  <tr><td>T(N)</td><td>&le;</td><td>c * N</td></tr>
  <tr><td>T(N)</td><td>&le;</td><td>7 * N</td></tr>
  <tr><td>6 * N + 4</td><td>&le;</td><td>7 * N</td></tr>
  <tr><td>4</td><td>&le;</td><td>N</td></tr>
</table>
We did it!  As long as N &ge; 4, then we're good.  So, n &ge; 4 and c == 7 are constants we can use to prove that T(N) &isin; O(N).  This also goes to show that choosing a c and n can be tricky.  What if we just didn't choose a c or n until we had to?  Let's find out:</p>
<table>
  <tr><td>T(N)</td><td>&le;</td><td>c * N</td></tr>
  <tr><td>6 * N + 4</td><td>&le;</td><td>c * N</td></tr>
  <tr><td>4</td><td>&le;</td><td>(c - 6) * N</td></tr>
  <tr><td>4 / (c - 6)</td><td>&ge;</td><td>N  (if c &lt; 6)</td></tr>
  <tr><td></td><td><strong>OR</strong></td><td></td></tr>
  <tr><td>4 / (c - 6)</td><td>&le;</td><td>N  (if c &gt; 6)</td></tr>
</table>
<p>At that last step, it's tempting to just divide both sides by c - 6, but if you do, you'd have to flip the &le; to &ge; if c - 6 is negative.  Since c must be greater than 6, we conclude that n &ge; 4 / (c - 6).  Note that this is sufficient to prove that T(N) is O(N), even though we didn't find the exact constants n and c, we proved that they exist.</p>
<p>We can also take this a step further and prove that any function T(N) = A * N + B for some constants A and B is O(N):</p>
<table>
  <tr><td>T(N)</td><td>&le;</td><td>c * N</td></tr>
  <tr><td>A * N + B</td><td>&le;</td><td>c * N</td></tr>
  <tr><td>B</td><td>&le;</td><td>c * N - A * N</td></tr>
  <tr><td>B</td><td>&le;</td><td>(c - A) * N</td></tr>
  <tr><td>B / (c - A)</td><td>&le;</td><td>N  (if c - A > 0)</td></tr>
  <tr><td>B / (c - A)</td><td>&le;</td><td>N  (if c > A)</td></tr>
</table>
<p>That's it!  All we have to do is set c == A + 1, then n == B / (c - A) == B / (A + 1 - A) == B.</p>

<h3>k * f(N) &isin; O(f(N))</h3>
<table>
  <tr><td>k * f(N)</td><td>&isin;</td><td>O(f(N))</td></tr>
  <tr><td>k * f(N)</td><td>&le;</td><td>c * f(N)</td></tr>
  <tr><td>k</td><td>&le;</td><td>c</td></tr>
</table>
<p>Now we've formally proven that a constant multiplier doesn't matter!</p>
<h3>f(N) + k &isin; O(f(N)); when f(N) &ge; x (x is a constant)</h3>
<table>
  <tr><td>f(N) + k</td><td>&isin;</td><td>O(f(N))</td></tr>
  <tr><td>f(N) + k</td><td>&le;</td><td>c * f(N)</td></tr>
  <tr><td>k</td><td>&le;</td><td>c * f(N) - f(N)</td></tr>
  <tr><td>k</td><td>&le;</td><td>(c - 1) * f(N)</td></tr>
  <tr><td>k / (c - 1)</td><td>&le;</td><td>f(N)</td></tr>
  <tr><td>k / (c - 1)</td><td>&le;</td><td>x</td><td>&le;</td><td>f(N)</td></tr>
  <tr><td>k / (c - 1)</td><td>&le;</td><td>x</td></tr>
  <tr><td>k</td><td>&le;</td><td>x * (c - 1)</td></tr>
  <tr><td>k / x</td><td>&le;</td><td>c - 1</td></tr>
  <tr><td>k / x + 1</td><td>&le;</td><td>c</td></tr>
</table>
<p>Now we've formally proven that a constant addition doesn't matter!</p>

<h3>Demonstration</h3>
<p>Here's a demonstration of big-O in action. The recursive solution starts out fast, with the iterative/looping solution second, and the math/closed-form solution last, but over time you can see that the recursive O(fibonacci(N)) one quickly becomes very slow, then the iterative O(N) solution, until the math-based O(1) solution is best.</p>
many_fibonacci.cpp<pre><code class="c++">#include &lt;chrono&gt;
#include &lt;cmath&gt;
#include &lt;cstdlib&gt;
#include &lt;cstdio&gt;

using namespace std::chrono;

// A class for timing how long something takes.
class SimpleTimer {
  high_resolution_clock::time_point start_time;
public:
  void start() {
    start_time = high_resolution_clock::now();
  }
  double seconds_elapsed() {
    return duration_cast&lt;duration&lt;double&gt;&gt;(
        high_resolution_clock::now() - start_time).count();
  }
};


// O(fibonacci(n)) run time
// O(log(n)) memory
long fibonacci_recursive(int n) {
  if (n &lt;= 1)
    return 1;
  return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2);
}


// 3 + (n + 1) * (5) + 1 == 5 * n + 9
long fibonacci_loop(int n) {
  long f0 = 0, f1 = 1, f2 = 1; // 3 assignments
  while (n &gt;= 0) { // n + 1 loopdy looooooops
    f2 = f1 + f0; // 2
    f0 = f1; // 1
    f1 = f2; // 1
    --n; // 1
  }
  return f2; // 1
}



// Search for &#34;Fibonacci closed form&#34; to learn how to calculate
// fibonacci(n) in &#39;O(1)&#39; time.
// O(1) run time and memory
long fibonacci_math(int n) {
  double sqrt_5 = sqrt(5);
  return (pow(1 + sqrt_5, n) - pow(1 - sqrt_5, n)) / (pow(2, n) * sqrt_5);
}

// This function returns the number of seconds taken to run
// fibonacci_function(n) num_times times.
// FibFunction is any callable (such as a function or any class that overloads
// operation()) that takes an int (or something that can be typecasted to an
// int) as input.  The return type of a FibFunction is ignored/irrelevant.
template&lt;typename FibFunction&gt;
double seconds_for_fib(FibFunction fibonacci_function, int n, int num_times) {
  SimpleTimer timer;
  timer.start();
  while (num_times--)
    fibonacci_function(n);
  return timer.seconds_elapsed();
}

int main() {
  int n;
  for (n = 0; ; n += 5) {
    double seconds_for_recursive = seconds_for_fib(fibonacci_recursive, n, 1);
    double seconds_for_loop = seconds_for_fib(fibonacci_loop, n, 100000);
    double seconds_for_math = seconds_for_fib(fibonacci_math, n, 1000000);
    printf(&#34;%4d | recursive %.6f | loop %.6f | math %.6f\n&#34;, n,
           seconds_for_recursive, seconds_for_loop, seconds_for_math);
    // When the recursive fibonacci solution gets too slow, break
    // so we can go to the next loop.
    if (seconds_for_recursive &gt; seconds_for_loop)
      break;
  }
  for (; ; n += 25) {
    double seconds_for_loop = seconds_for_fib(fibonacci_loop, n, 100000);
    double seconds_for_math = seconds_for_fib(fibonacci_math, n, 1000000);
    printf(&#34;%4d | recursive  &lt;slow&gt;  | loop %.6f | math %.6f\n&#34;, n,
           seconds_for_loop, seconds_for_math);
    if (seconds_for_loop &gt; seconds_for_math)
      break;
  }
  return 0;
}</code></pre><pre><strong>$</strong> <kbd>clang -pedantic -Wall -lm -lstdc++ -lpthread -std=c++11 -o example many_fibonacci.cpp</kbd>
<strong>$</strong> <kbd>./example</kbd></pre><pre><samp>   0 | recursive 0.000000 | loop 0.000483 | math 0.018701
   5 | recursive 0.000000 | loop 0.001268 | math 0.158227
  10 | recursive 0.000001 | loop 0.002401 | math 0.156433
  15 | recursive 0.000004 | loop 0.003712 | math 0.158944
  20 | recursive 0.000041 | loop 0.005116 | math 0.156044
  25 | recursive 0.000454 | loop 0.006621 | math 0.164762
  30 | recursive 0.005296 | loop 0.009245 | math 0.162666
  35 | recursive 0.057281 | loop 0.010481 | math 0.164338
  35 | recursive  &lt;slow&gt;  | loop 0.010483 | math 0.163999
  60 | recursive  &lt;slow&gt;  | loop 0.018253 | math 0.157002
  85 | recursive  &lt;slow&gt;  | loop 0.025479 | math 0.162065
 110 | recursive  &lt;slow&gt;  | loop 0.034803 | math 0.164901
 135 | recursive  &lt;slow&gt;  | loop 0.042864 | math 0.167312
 160 | recursive  &lt;slow&gt;  | loop 0.048777 | math 0.157801
 185 | recursive  &lt;slow&gt;  | loop 0.056114 | math 0.158182
 210 | recursive  &lt;slow&gt;  | loop 0.063627 | math 0.163061
 235 | recursive  &lt;slow&gt;  | loop 0.075082 | math 0.166130
 260 | recursive  &lt;slow&gt;  | loop 0.083172 | math 0.162355
 285 | recursive  &lt;slow&gt;  | loop 0.089688 | math 0.158131
 310 | recursive  &lt;slow&gt;  | loop 0.094236 | math 0.162542
 335 | recursive  &lt;slow&gt;  | loop 0.108222 | math 0.165466
 360 | recursive  &lt;slow&gt;  | loop 0.112760 | math 0.156813
 385 | recursive  &lt;slow&gt;  | loop 0.117398 | math 0.157928
 410 | recursive  &lt;slow&gt;  | loop 0.128615 | math 0.164295
 435 | recursive  &lt;slow&gt;  | loop 0.139260 | math 0.160449
 460 | recursive  &lt;slow&gt;  | loop 0.141381 | math 0.157003
 485 | recursive  &lt;slow&gt;  | loop 0.147676 | math 0.159946
 510 | recursive  &lt;slow&gt;  | loop 0.159797 | math 0.160488
 535 | recursive  &lt;slow&gt;  | loop 0.164046 | math 0.158811
</samp></pre>

<h2>Exponential Big-O</h2>
<table>
  <tr><td>O(pow(2, n))</td><td> =?= </td><td>O(pow(3, n))</td></tr>
  <tr><td>O(1)</td><td> =?= </td><td>O(pow(3, n) / pow(2, n))</td></tr>
  <tr><td>O(1)</td><td> != </td><td>O(pow(1.5, n))</td></tr>
</table>
<p>There's also a <a href="http://stackoverflow.com/questions/19081673/big-o-notation-of-exponential-functions/19081711#19081711">short explanation on Stack Overflow</a>, but it requires knowing a bit of the <a href="https://xlinux.nist.gov/dads/HTML/bigOnotation.html">math/definition of big-O</a>.</p>




</section>
<footer>Copyright 2016 by Mikel Dmitri Mcdaniel -- Under the <a href="license.html">MIT License</a></footer>
</body>
</html>