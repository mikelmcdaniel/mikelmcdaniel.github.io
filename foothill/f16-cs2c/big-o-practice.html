<!doctype html>
<html>
<head>
<title>Big-O Practice</title>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.2.0/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.2.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head>
<body>
<section>
  

<h2>Big-O Practice</h2>
<h3>O(N)</h3>
<pre><code class="c++">for (register uint32 y = 0; y &lt; GFX.StartY; y++)
{
	register uint16	*p = GFX.Screen + y * GFX.PPL + 255;
	register uint16	*q = GFX.Screen + y * GFX.PPL + 510;

	for (register int x = 255; x &gt;= 0; x--, p--, q -= 2)
		*q = *(q + 1) = *p;
}</code></pre>
- <a href="https://github.com/snes9xgit/snes9x/blob/master/gfx.cpp#L697">snes9x/gfx.cpp:697</a>
<p>This code looks complicated, but if you look at it step by step, it starts to make sense. Let's consider the outer for-loop: At first glance it appears to be O(<code>GFX.StartY</code>) and after looking elsewhere in the for-loop, we see that nothing else changes <code>y</code> or <code>GFX.StartY</code>, so it's O(<code>GFX.StartY</code>). But what about the inner-loop? Whatever big-O the inner-loop has would be multiplied by the big-O of the outer-loop to give us the total big-O for this piece of code. If we look at the for-loop declaration we see that <code>x</code> is initially 255 and is decremented until it reaches -1, so the loop runs exactly 255 + 1 times... so the inner loop is actually O(256) == O(1). Everything else in this code is O(1). Therefore, the big-O of this piece of code is O(<code>GFX.StartY</code>)!</p>

<h3>O(log(N))</h3>
<p>Let's just consider the big-O of <code>simple_binary_search</code>:</p>
<pre><code class="c++">#include &lt;iostream&gt;

// Return the index of x in ints, between low_index and high_index.
// If x is not in ints between low_index and high_index, we return -1.
// Note that low_index is inclusive, meaning that we are considering that
// x could be at ints[low_index], but that high_index is exlusive, meaning
// that we won't check ints[high_index], but we may check ints[high_index - 1].
int simple_binary_search(const int ints[], const int x,
                         const int low_index, const int high_index) {
  // Base Case:
  if (high_index - low_index &lt;= 0) {
    // We were asked to search a section of the ints array that is empty
    // we should return -1 since we know that there's nothing.
    return -1;
  }
  // General Case:
  int middle_index = (low_index + high_index) / 2;
  if (ints[middle_index] &lt; x) {
    // Since the ints is sorted *and* ints[middle_index] &lt; x, we know that x
    // must be in somewhere between middle_index and high_index.
    // Since we already checked middle_index and our lower index is exclusive,
    // we pass middle_index + 1 as the new low_index.
    return simple_binary_search(ints, x, middle_index + 1, high_index);
  } else if (ints[middle_index] &gt; x) {
    // Since the ints is sorted *and* ints[middle_index] &lt; x, we know
    // that x must be in somewhere between low_index and middle_index.
    return simple_binary_search(ints, x, low_index, middle_index);
  } else { // if (ints[middle_index] == x)
    // We found x.
    return middle_index;
  }
}

int main() {
  const int sorted_ints[] = {0, 10, 20, 30, 40, 50, 60, 70, 80, 90};
  int num_ints = sizeof(sorted_ints) / sizeof(sorted_ints[0]);

  std::cout &lt;&lt; "const int sorted_ints[] = {" &lt;&lt; sorted_ints[0];
  for (int i = 1; i &lt; num_ints; ++i) {
    std::cout &lt;&lt; ", " &lt;&lt; sorted_ints[i];
  }
  std::cout &lt;&lt; "};" &lt;&lt; std::endl;

  // This loop searches for sorted_ints[i] + offset using simple_binary_search.
  // The offset is just to demonstrate that simple_binary_search still works
  // when we try to search for something that doesn't exist.
  for (int offset = -1; offset &lt; 2; ++offset) {
    std::cout &lt;&lt; std::endl;
    for (int i = 0; i &lt; num_ints; ++i) {
      std::cout
        &lt;&lt; "simple_binary_search(sorted_ints, " &lt;&lt; sorted_ints[i] + offset
        &lt;&lt; ", 0, " &lt;&lt; num_ints &lt;&lt; ") == "
        &lt;&lt; simple_binary_search(sorted_ints, sorted_ints[i] + offset, 0, num_ints)
        &lt;&lt; std::endl;
    }
  }
}
</code></pre>
<p>You may already have heard that <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm#Performance">Binary Search is O(log(N))</a>, but let's prove it. Consider the recursive algorithm: We start out with an array (vector or somethine else) with N elements. In the worst case, such as when the element we're looking for isn't in the array, we have to keep recursing until we get to a range with only 1 element it. At that point, it's just an O(1) to see if the element is the one we're looking for or not. Let's call the number of times we have to recurse R. Each time we recurse, the range is cut in half, so after recursing once, we're now looking at N/2 elements and after recursing R times, we're looking at N / pow(2, R) elements. Since, in the worst case, we stop recursing when we look at 1 element, then we know that N / pow(2, R) == 1, so:
<table>
  <tr><td>N / pow(2, R)</td><td>=</td><td>1</td></tr>
  <tr><td>N</td><td>=</td><td>pow(2, R)</td></tr>
  <tr><td>log(N) / log(2)</td><td>=</td><td>log(pow(2, R)) / log(2)</td></tr>
  <tr><td>log(N) / log(2)</td><td>=</td><td>R</td></tr>
</table>
That's it! We know that in the worst case, we only have to recurse log(N) times. Since everything else that Binary Search does is O(1), the Binary Search is O(log(N))!
</p>


<h3>O(N * log(N))</h3>
<p>Let's just consider the big-O of <code>merge_sort</code>:</p>

<pre><code class="c++">#include &lt;iostream&gt;
#include &lt;vector&gt;

// Take two InputIterator ranges (begin and end iterators) that point to sorted
// data, then merge those sorted ranges and output into the OutputIterator.
template &lt;typename InputIterator, typename OutputIterator&gt;
void merge_sorted_iters(InputIterator iter1, InputIterator iter1_end,
                        InputIterator iter2, InputIterator iter2_end,
                        OutputIterator output) {
  // while there are values left in [iter1, iter1_end) and [iter2, iter2_end),
  // keep taking the smaller value from either *iter1 or *iter2 and copy it to
  // *output.
  while (iter1 != iter1_end &amp;&amp; iter2 != iter2_end) {
    if (*iter1 &lt; *iter2) {
      // *iter1 is smaller than *iter2, so copy it
      *output = *iter1;
      ++output;
      ++iter1;
    } else {
      // *iter2 is smaller than (or equal to) *iter1, so copy it
      *output = *iter2;
      ++output;
      ++iter2;
    }
  }
  // There might values remaining in [iter1, iter1_end), so copy them.
  // Note that if there is anything in [iter1, iter1_end), then
  // [iter2, iter2_end) must be empty since we exited the first while-loop.
  while (iter1 != iter1_end) {
    *output = *iter1;
    ++output;
    ++iter1;
  }
  // The same logic applies here:
  while (iter2 != iter2_end) {
    *output = *iter2;
    ++output;
    ++iter2;
  }
}

template &lt;typename T&gt;
void merge_sort_helper(std::vector&lt;T&gt;&amp; unsorted, T* scratch,
                       int low, int high) {
  // if [low, high) has 1 element, it's already sorted.
  if (high - low &lt;= 1) {
    return;
  }

  int middle = (low + high) / 2;

  // sort the left half: [low, middle)
  merge_sort_helper(unsorted, scratch, low, middle);
  // sort the right half: [middle, high)
  merge_sort_helper(unsorted, scratch, middle, high);

  // merge the left/right halves into scratch
  merge_sorted_iters(unsorted.begin() + low, unsorted.begin() + middle,
                     unsorted.begin() + middle, unsorted.begin() + high,
                     scratch + low);

  // copy the merged halves from scratch back to unsorted
  for (int i = low; i &lt; high; ++i) {
    unsorted[i] = scratch[i];
  }
}

template &lt;typename T&gt;
void merge_sort(std::vector&lt;T&gt;&amp; unsorted) {
  T *scratch = new T[unsorted.size()];
  merge_sort_helper(unsorted, scratch, 0, unsorted.size());
  delete scratch;
}


int main() {
  std::vector&lt;int&gt; sorted = {1, 10, 4, 2, 5, 0, 6, 9};

  merge_sort(sorted);

  std::cout &lt;&lt; "sorted numbers: [";
  for (const int&amp; x : sorted) {
    std::cout &lt;&lt; x &lt;&lt; " ";
  }
  std::cout &lt;&lt; "]\n";
  return 0;
}
</code></pre>
<p><a href="https://en.wikipedia.org/wiki/Merge_sort#Analysis">Merge Sort</a> is a bit more work to analyze, but is still quite similar. Let's consider the big-O of <code>merge_sorted_iters</code> first. <code>iter1</code> to <code>iter1_end</code> represent some range of numbers and <code>iter2</code> to <code>iter2_end</code> similarly represent a range of numbers. Let's say they're of length L1 and L2, respectively. In each of the while-loops, every iteration of the while loop will end up incrementing either <code>iter1</code> or <code>iter2</code>, making that range 1 smaller until the ranges are empty. So, the sum of the number of times each loop runs is just L1 + L2. Since each loop does O(1) work inside of them, then the <code>merge_sorted_iters</code> is O(L1 + L2).</p>
<p>Now, let's consider the big-O of <code>merge_sort_helper</code>. First, it has an O(1) base case that returns if the input size, N, is &le; 1. Then it calls itself on the left and right halves, then it merges the left and right halves into <code>scratch</code>, which is O(N), and finally copies from <code>scratch</code> back to <code>unsorted</code>, which is also O(N). What if we visualize this? Imagine that each row below represents some calls to <code>merge_sort_helper</code>, with the row below representing all the calls from the layer above:
<table style="text-align:center" border="1">
  <tr><td colspan="64">N elements</td></tr>
  <tr><td colspan="32">N / 2</td><td colspan="32">N / 2</td></tr>
  <tr><td colspan="16">N / 4</td><td colspan="16">N / 4</td><td colspan="16">N / 4</td><td colspan="16">N / 4</td></tr>
  <tr><td colspan="8">N / 8</td><td colspan="8">N / 8</td><td colspan="8">N / 8</td><td colspan="8">N / 8</td><td colspan="8">N / 8</td><td colspan="8">N / 8</td><td colspan="8">N / 8</td><td colspan="8">N / 8</td></tr>
  <tr><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td><td colspan="4">N / 16</td></tr>
  <tr><td colspan="64">. . .</td></tr>
  <tr><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>
</table>
Every row has N total elements in it, and we know that any call to <code>merge_sort_helper</code> is O(N) + O(the recursive calls). In other words, the big-O of the call at the top, with N elements, is O(N) + O(the calls below it). Let's number the rows, with the top one being 0, the second layer being 1, and the rth layer being r - 1. Let's also call the number of rows or depth of recursion, R. At layer 0, there's 1 call that does O(N) work, except for recursing. At layer 1, there's 2 calls that do O(N / 2) work, which is O(N) in total. At layer r, there's pow(2, r) calls that do O(N / pow(2, r)) work, which is O(N) in total. By this logic, the total work must be O(N * R). We know that the recursion stops when we make calls to <code>merge_sort_helper</code> with 1 (or fewer) elements, so:
<table>
  <tr><td>N / pow(2, R)</td><td>=</td><td>1</td></tr>
  <tr><td>N</td><td>=</td><td>pow(2, R)</td></tr>
  <tr><td>log(N) / log(2)</td><td>=</td><td>log(pow(2, R)) / log(2)</td></tr>
  <tr><td>log(N) / log(2)</td><td>=</td><td>R</td></tr>
</table>
Now, we know that Merge Sort is O(N * log(N)).
</p>
<p>Another, more direct and mathematical, approach is to let T(N) be 'order of' the running time and remember that if <code>merge_sort_helper</code> does some O(1), calls itself on the left and right halves, then does O(N) work, so T(N) = 1 + 2 * T(N / 2) + N and try to simplify it:
<table>
  <tr><td>T(N)</td><td>=</td><td>2 * T(N / 2) + N + 1</td></tr>
  <tr><td></td><td>=</td><td>2 * (2 * T(N / 4) + N / 2 + 1) + N + 1</td></tr>
  <tr><td></td><td>=</td><td>4 * T(N / 4) + 2 * N + 3</td></tr>
  <tr><td></td><td>=</td><td>4 * (2 * T(N / 8) + N / 4 + 1) + 2 * N + 3</td></tr>
  <tr><td></td><td>=</td><td>8 * T(N / 8) + 3 * N + 7</td></tr>
  <tr><td></td><td>=</td><td>8 * (2 * T(N / 16) + N / 8 + 1) + 3 * N + 7</td></tr>
  <tr><td></td><td>=</td><td>16 * T(N / 16) + 4 * N + 15</td></tr>
  <tr><td colspan="3">. . .</td></tr>
  <tr><td>T(N)</td><td>=</td><td>pow(2, R) * T(N / pow(2, R)) + R * N + (1 + 2 + ... + pow(2, R - 1))</td></tr>
  <tr><td></td><td>=</td><td>pow(2, R) * T(N / pow(2, R)) + R * N + pow(2, R) - 1</td></tr>
  <tr><td></td><td>=</td><td>pow(2, log(N) / log(2)) * T(N / pow(2, log(N) / log(2))) + log(N) / log(2) * N + pow(2, log(N) / log(2)) - 1</td></tr>
  <tr><td></td><td>=</td><td>N * T(N / N) + log(N) / log(2) * N + N - 1</td></tr>
  <tr><td></td><td>=</td><td>N * 1 + log(N) / log(2) * N + N - 1</td></tr>
  <tr><td>T(N)</td><td>=</td><td>N * log(N) / log(2) + 2 * N - 1</td></tr>
</table>
Now, if we eliminate the lower-order terms, we see that T(N) &isin; O(N * log(N)).
</p>


</section>
<footer>Copyright 2016 by Mikel Dmitri Mcdaniel -- Under the <a href="license.html">MIT License</a></footer>
</body>
</html>